---
title: "chapter 14-1"
author: "Min-Yao"
date: "2020/3/5"
output: 
  html_document: 
    keep_md: yes
---

# 14 Adventures in Covariance

## 14.1. Varying slopes by construction

### 14.1.1. Simulate the population.

```{r}
library(rethinking)

## R code 14.1
a <- 3.5            # average morning wait time
b <- (-1)           # average difference afternoon wait time
sigma_a <- 1        # std dev in intercepts
sigma_b <- 0.5      # std dev in slopes
rho <- (-0.7)       # correlation between intercepts and slopes

## R code 14.2
Mu <- c( a , b )

## R code 14.3
cov_ab <- sigma_a*sigma_b*rho
Sigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 )

## R code 14.4
matrix( c(1,2,3,4) , nrow=2 , ncol=2 )

## R code 14.5
sigmas <- c(sigma_a,sigma_b) # standard deviations
Rho <- matrix( c(1,rho,rho,1) , nrow=2 ) # correlation matrix

# now matrix multiply to get covariance matrix
Sigma <- diag(sigmas) %*% Rho %*% diag(sigmas)

## R code 14.6
N_cafes <- 20

## R code 14.7
library(MASS)
set.seed(5) # used to replicate example
vary_effects <- mvrnorm( N_cafes , Mu , Sigma )

## R code 14.8
a_cafe <- vary_effects[,1]
b_cafe <- vary_effects[,2]

## R code 14.9
plot( a_cafe , b_cafe , col=rangi2,
    xlab="intercepts (a_cafe)" , ylab="slopes (b_cafe)" )

# overlay population distribution
library(ellipse)
for ( l in c(0.1,0.3,0.5,0.8,0.99) )
    lines(ellipse(Sigma,centre=Mu,level=l),col=col.alpha("black",0.2))
```

### 14.1.2. Simulate observations.

```{r}
## R code 14.10
set.seed(22)
N_visits <- 10
afternoon <- rep(0:1,N_visits*N_cafes/2)
cafe_id <- rep( 1:N_cafes , each=N_visits )
mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon
sigma <- 0.5  # std dev within cafes
wait <- rnorm( N_visits*N_cafes , mu , sigma )
d <- data.frame( cafe=cafe_id , afternoon=afternoon , wait=wait )
```

### 14.1.3. The varying slopes model.

```{r}
## R code 14.11
R <- rlkjcorr( 1e4 , K=2 , eta=2 )
dens( R[,1,2] , xlab="correlation" )
```

```{r}
### Rho ~ lkj_corr(2)
## R code 14.12
m14.1 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE )

## R code 14.13
post <- extract.samples(m14.1)
dens( post$Rho[,1,2] )

precis(m14.1)
```

```{r}
### Rho ~ lkj_corr(1)
## R code 14.12
m14.1_c1 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(1)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE )

## R code 14.13
post <- extract.samples(m14.1_c1)
dens( post$Rho[,1,2] )

precis(m14.1_c1)
```

```{r}
### Rho ~ lkj_corr(5)
## R code 14.12
m14.1_c5 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(5)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE )

## R code 14.13
post <- extract.samples(m14.1_c5)
dens( post$Rho[,1,2] )

precis(m14.1_c5)
```

```{r}
compare(m14.1, m14.1_c1, m14.1_c5)
```


```{r}
## R code 14.14
# compute unpooled estimates directly from data
a1 <- sapply( 1:N_cafes ,
        function(i) mean(wait[cafe_id==i & afternoon==0]) )
b1 <- sapply( 1:N_cafes ,
        function(i) mean(wait[cafe_id==i & afternoon==1]) ) - a1

# extract posterior means of partially pooled estimates
post <- extract.samples(m14.1)
a2 <- apply( post$a_cafe , 2 , mean )
b2 <- apply( post$b_cafe , 2 , mean )

# plot both and connect with lines
plot( a1 , b1 , xlab="intercept" , ylab="slope" ,
    pch=16 , col=rangi2 , ylim=c( min(b1)-0.1 , max(b1)+0.1 ) ,
    xlim=c( min(a1)-0.1 , max(a1)+0.1 ) )
points( a2 , b2 , pch=1 )
for ( i in 1:N_cafes ) lines( c(a1[i],a2[i]) , c(b1[i],b2[i]) )

## R code 14.15
# compute posterior mean bivariate Gaussian
Mu_est <- c( mean(post$a) , mean(post$b) )
rho_est <- mean( post$Rho[,1,2] )
sa_est <- mean( post$sigma_cafe[,1] )
sb_est <- mean( post$sigma_cafe[,2] )
cov_ab <- sa_est*sb_est*rho_est
Sigma_est <- matrix( c(sa_est^2,cov_ab,cov_ab,sb_est^2) , ncol=2 )

# draw contours
library(ellipse)
for ( l in c(0.1,0.3,0.5,0.8,0.99) )
    lines(ellipse(Sigma_est,centre=Mu_est,level=l),
        col=col.alpha("black",0.2))
```

```{r}
## R code 14.16
# convert varying effects to waiting times
wait_morning_1 <- (a1)
wait_afternoon_1 <- (a1 + b1)
wait_morning_2 <- (a2)
wait_afternoon_2 <- (a2 + b2)

# plot both and connect with lines
plot( wait_morning_1 , wait_afternoon_1 , xlab="morning wait" ,
    ylab="afternoon wait" , pch=16 , col=rangi2 ,
    ylim=c( min(wait_afternoon_1)-0.1 , max(wait_afternoon_1)+0.1 ) ,
    xlim=c( min(wait_morning_1)-0.1 , max(wait_morning_1)+0.1 ) )
points( wait_morning_2 , wait_afternoon_2 , pch=1 )
for ( i in 1:N_cafes )
    lines( c(wait_morning_1[i],wait_morning_2[i]) ,
    c(wait_afternoon_1[i],wait_afternoon_2[i]) )
abline( a=0 , b=1 , lty=2 )

## R code 14.17
# now shrinkage distribution by simulation
v <- mvrnorm( 1e4 , Mu_est , Sigma_est )
v[,2] <- v[,1] + v[,2] # calculate afternoon wait
Sigma_est2 <- cov(v)
Mu_est2 <- Mu_est
Mu_est2[2] <- Mu_est[1]+Mu_est[2]

# draw contours
library(ellipse)
for ( l in c(0.1,0.3,0.5,0.8,0.99) )
    lines(ellipse(Sigma_est2,centre=Mu_est2,level=l),
        col=col.alpha("black",0.5))
```

## 14.7. Practice

### Easy.
#### 14E1. Add to the following model varying slopes on the predictor x.

$$
y _i ∼ Normal(µ_i, σ) \\
µi = α _{group[i]} + βx_i \\
α_{group} ∼ Normal(α, σ _α ) \\
α ∼ Normal(0, 10) \\
β ∼ Normal(0, 1) \\
σ ∼ HalfCauchy(0, 2) \\
σ _α ∼ HalfCauchy(0, 2) \\
$$

#### model with varying slopes

$$
y _i ∼ Normal(µ_i, σ) \\
µi = α _{group[i]} + β _{group[i]}*x_i \\
\begin{bmatrix}α _{group}\\
β _{group}
\end{bmatrix} \sim MVNormal( \begin{bmatrix}α\\
β
\end{bmatrix} , S ) \\
S = \begin{pmatrix}σ _α & 0\\
0 & σ _α
\end{pmatrix} * R * \begin{pmatrix}σ _α & 0\\
0 & σ _α
\end{pmatrix} \\
α ∼ Normal(0, 10) \\
β ∼ Normal(0, 1) \\
σ ∼ HalfCauchy(0, 2) \\
σ _α ∼ HalfCauchy(0, 2) \\
σ _β ∼ HalfCauchy(0, 2) \\
R \sim LKJcorr(2) \\
$$

#### 14E2. Think up a context in which varying intercepts will be positively correlated with varying slopes. Provide a mechanistic explanation for the correlation.

> Lignin_amount_in_cortex ~ a[cultivar] + b[cultivar]*developmental_stage

> Different tomato cultivars accumulate different amount of lignin in their cortex region in response to Cuscuta. Resistant cultivars accumulate more lignin than susceptible cultivars. And, their developmental stages also influence the amount of lignin accumulation. Usually older plants accumulate more lignin in stem.

#### 14E3. When is it possible for a varying slopes model to have fewer effective parameters (as estimated by WAIC or DIC) than the corresponding model with fixed (unpooled) slopes? Explain.

> It might happen when intercepts & slopes are highly correlated across groups. Because we treats correlation between intercepts & slopes independently for each group in the unpooled model; on the other hand, the pooled model relies on common distribution that can reduce the number of parameters.

### Medium.
#### 14M1. Repeat the café robot simulation from the beginning of the chapter. This time, set rho to zero, so that there is no correlation between intercepts and slopes. How does the posterior distribution of the correlation reflect this change in the underlying simulation?

```{r}
library(rethinking)

## R code 14.1
a <- 3.5            # average morning wait time
b <- (-1)           # average difference afternoon wait time
sigma_a <- 1        # std dev in intercepts
sigma_b <- 0.5      # std dev in slopes
rho <- 0       # correlation between intercepts and slopes

## R code 14.2
Mu <- c( a , b )

## R code 14.3
cov_ab <- sigma_a*sigma_b*rho
Sigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 )

## R code 14.4
matrix( c(1,2,3,4) , nrow=2 , ncol=2 )

## R code 14.5
sigmas <- c(sigma_a,sigma_b) # standard deviations
Rho <- matrix( c(1,rho,rho,1) , nrow=2 ) # correlation matrix

# now matrix multiply to get covariance matrix
Sigma <- diag(sigmas) %*% Rho %*% diag(sigmas)

## R code 14.6
N_cafes <- 20

## R code 14.7
library(MASS)
set.seed(5) # used to replicate example
vary_effects <- mvrnorm( N_cafes , Mu , Sigma )

## R code 14.8
a_cafe <- vary_effects[,1]
b_cafe <- vary_effects[,2]

## R code 14.9
plot( a_cafe , b_cafe , col=rangi2,
    xlab="intercepts (a_cafe)" , ylab="slopes (b_cafe)" )

# overlay population distribution
library(ellipse)
for ( l in c(0.1,0.3,0.5,0.8,0.99) )
    lines(ellipse(Sigma,centre=Mu,level=l),col=col.alpha("black",0.2))
```

> Simulate observations.

```{r}
## R code 14.10
set.seed(22)
N_visits <- 10
afternoon <- rep(0:1,N_visits*N_cafes/2)
cafe_id <- rep( 1:N_cafes , each=N_visits )
mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon
sigma <- 0.5  # std dev within cafes
wait <- rnorm( N_visits*N_cafes , mu , sigma )
d <- data.frame( cafe=cafe_id , afternoon=afternoon , wait=wait )
```

```{r}
## R code 14.11
R <- rlkjcorr( 1e4 , K=2 , eta=2 )
dens( R[,1,2] , xlab="correlation" )
```

```{r}
### Rho ~ lkj_corr(2)
## R code 14.12
m14M1 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE )

## R code 14.13
post <- extract.samples(m14.1)
dens( post$Rho[,1,2] )
precis(m14.1)
precis(m14M1)
```

> there is no correlation between intercepts and slopes.

#### 14M2. Fit this multilevel model to the simulated café data:
W i ∼ Normal(µi, σ)
µi = α café[i] + β café[i] A i
αcafé ∼ Normal(α, σ α )
βcafé ∼ Normal(β, σ β )
α ∼ Normal(0, 10)
β ∼ Normal(0, 10)
σ ∼ HalfCauchy(0, 1)
σ α ∼ HalfCauchy(0, 1)
σ β ∼ HalfCauchy(0, 1)

#### Use WAIC to compare this model to the model from the chapter, the one that uses a multi-variate Gaussian prior. Explain the result.

```{r}
## R code 14.12
m14M2.1 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        a_cafe[cafe] ~ normal(a, a_sigma),
        b_cafe[cafe] ~ normal(b, b_sigma),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma ~ exponential(1),
        a_sigma ~ exponential(1),
        b_sigma ~ exponential(1)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE)

precis(m14M2.1)

```

```{r}
## R code 14.12
m14M2.2 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        a_cafe[cafe] ~ normal(a, a_sigma),
        b_cafe[cafe] ~ normal(b, b_sigma),
        a ~ normal(0,10),
        b ~ normal(0,10),
        sigma ~ dcauchy(0,1),
        a_sigma ~ dcauchy(0,1),
        b_sigma ~ dcauchy(0,1)
    ) , data=d , chains=4 , cores=4, log_lik = TRUE)

precis(m14M2.2)
```

```{r}
compare(m14.1, m14M2.1, m14M2.2)
```




#### 14M3. Re-estimate the varying slopes model for the UCBadmit data, now using a non-centered parameterization. Compare the efficiency of the forms of the model, using n_eff. Which is better? Which chain sampled faster?

